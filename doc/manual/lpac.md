\page lpac LPAC Architecture

## Navigation of Robot Swarms
Navigating a swarm of robots through an environment to achieve a common collaborative goal is a challenging problem, especially when the sensing and communication capabilities of the robots are limited.
These problems require systems with high-fidelity algorithms comprising three key capabilities: perception, action, and communication, which are executed in a feedback loop, i.e., the Perception-Action-Communication (PAC) loop.
To seamlessly scale the deployment of such systems across vast environments with large robot swarms, it is imperative to consider a decentralized system wherein each robot autonomously makes decisions, drawing upon its own observations and information received from neighboring robots.

## The Challenge
However, designing a navigation algorithm for a decentralized system is challenging.
The robots perform perception and action independently, while the communication module is the only component that can facilitate robot collaboration.
Under limited communication capabilities, the robots must decide _what_ information to communicate to their neighbors and _how_ to use the received information to take appropriate actions.
The motivation of designing this library is to study the coverage control problem as a canonical problem for the decentralized navigation of robot swarms.
We develop the learnable PAC (LPAC) architecture that can learn to process sensor observations, communicate relevant information, and take appropriate actions.

## LPAC Architecture
The learnable Perception-Action-Communication (LPAC) architecture is composed of three different types of neural networks, one for each module of the PAC system.
1. In the perception module, a convolution neural network (CNN) processes localized IDF observations and generates an abstract representation.
2. In the communication module, a GNN performs computation on the output of the perception module and the messages received from neighboring robots.
It generates a fixed-size message to communicate with the neighbors and aggregates the received information to generate a feature vector for the action module of the robot.
3. In the action module, a shallow multilayer perceptron (MLP) predicts the control actions of the robot based on the feature vector generated by the GNN.

\htmlonly
<img class="center" style="width: 80%; margin-left: auto; margin-right: auto;" src="learnable_pac.png"/>
<figcaption>A near-optimal solution, along with Voronoi partition, to an instance of the coverage control problem with 32 robots and 32 features in a 1024 x 1024 environment.</figcaption>
\endhtmlonly

> [LPAC: Learnable Perception-Action-Communication Loops with Applications to Coverage Control.](https://doi.org/10.48550/arXiv.2401.04855)  
> Saurav Agarwal, Ramya Muthukrishnan, Walker Gosrich, Vijay Kumar, and Alejandro Ribeiro.  
> arXiv preprint arXiv:2401.04855 (2024).

